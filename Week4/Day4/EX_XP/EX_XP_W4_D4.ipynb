{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 1: Duplicate Detection and Removal\n",
        "Instructions\n",
        "Objective: Identify and remove duplicate entries in the Titanic dataset.\n",
        "\n",
        "Load the Titanic dataset.\n",
        "Identify if there are any duplicate rows based on all columns.\n",
        "Remove any duplicate rows found in the dataset.\n",
        "Verify the removal of duplicates by checking the number of rows before and after the duplicate removal.\n",
        "Hint: Use the duplicated() and drop_duplicates() functions in Pandas.\n",
        "\n"
      ],
      "metadata": {
        "id": "9UBEu1D3o0Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/titanic_ds.csv')\n",
        "duplicates = df.duplicated()\n",
        "duplicates_qty = duplicates.sum()\n",
        "rows_before = df.shape[0]\n",
        "df = df.drop_duplicates()\n",
        "rows_after = df.shape[0]\n",
        "print(f\"Number of rows before: {rows_before}\")\n",
        "print(f\"Number of rows after: {rows_after}\")\n",
        "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1V-F6fro6WH",
        "outputId": "3e91685d-1301-4eeb-e5b4-48354209c14b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows before: 418\n",
            "Number of rows after: 418\n",
            "Number of duplicate rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 2: Handling Missing Values\n",
        "Instructions\n",
        "Identify columns in the Titanic dataset with missing values.\n",
        "Explore different strategies for handling missing data, such as removal, imputation, and filling with a constant value.\n",
        "Apply each strategy to different columns based on the nature of the data.\n",
        "Hint: Review methods like dropna(), fillna(), and SimpleImputer from scikit-learn."
      ],
      "metadata": {
        "id": "AUR4I1I-qSEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "df = pd.read_csv('/content/titanic_ds.csv')\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Columns with missing values:\\n\", missing_values[missing_values > 0])\n",
        "# Strategy 1: Removal\n",
        "df_dropped = df.dropna()\n",
        "# Strategy 2: Imputation\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "# Strategy 3: Filling with a constant value\n",
        "df['Age'] = df['Age'].fillna(0)\n",
        "df['Embarked'] = df['Embarked'].fillna('Unknown')\n",
        "print(\"Data after handling missing values:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU23kL_VqrO0",
        "outputId": "688cff98-9ee1-4cbd-f7c8-031aaa959315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values:\n",
            " Age       86\n",
            "Fare       1\n",
            "Cabin    327\n",
            "dtype: int64\n",
            "Data after handling missing values:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0        892.0       0.0     3.0   \n",
            "1        893.0       1.0     3.0   \n",
            "2        894.0       0.0     2.0   \n",
            "3        895.0       0.0     3.0   \n",
            "4        896.0       1.0     3.0   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5    0.0    0.0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0    1.0    0.0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0    0.0    0.0   \n",
            "3                              Wirz, Mr. Albert    male  27.0    0.0    0.0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0    1.0    1.0   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "Shape after dropping rows: (87, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 3: Feature Engineering\n",
        "Instructions\n",
        "Create new features, such as Family Size from SibSp and Parch, and Title extracted from the Name column.\n",
        "Convert categorical variables into numerical form using techniques like one-hot encoding or label encoding.\n",
        "Normalize or standardize numerical features if required.\n",
        "Hint: Utilize Pandas for data manipulation and scikit-learnâ€™s preprocessing module for encoding.\n",
        "\n"
      ],
      "metadata": {
        "id": "fIoSFRYju9Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "df = pd.read_csv('/content/titanic_ds.csv')\n",
        "df['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n",
        "df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
        "print(df[['Name', 'Family_Size', 'Title']].head())\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Title'])\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UixsN3QvFJp",
        "outputId": "fe3b317f-a468-4852-aac2-19cad864faef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Name  Family_Size Title\n",
            "0                              Kelly, Mr. James            1    Mr\n",
            "1              Wilkes, Mrs. James (Ellen Needs)            2   Mrs\n",
            "2                     Myles, Mr. Thomas Francis            1    Mr\n",
            "3                              Wirz, Mr. Albert            1    Mr\n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)            3   Mrs\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name   Age  SibSp  Parch   Ticket  \\\n",
            "0                              Kelly, Mr. James  34.5      0      0   330911   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  47.0      1      0   363272   \n",
            "2                     Myles, Mr. Thomas Francis  62.0      0      0   240276   \n",
            "3                              Wirz, Mr. Albert  27.0      0      0   315154   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0      1      1  3101298   \n",
            "\n",
            "      Fare Cabin  ...  Embarked_S  Title_Col  Title_Dona  Title_Dr  \\\n",
            "0   7.8292   NaN  ...       False      False       False     False   \n",
            "1   7.0000   NaN  ...        True      False       False     False   \n",
            "2   9.6875   NaN  ...       False      False       False     False   \n",
            "3   8.6625   NaN  ...        True      False       False     False   \n",
            "4  12.2875   NaN  ...        True      False       False     False   \n",
            "\n",
            "   Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  \n",
            "0         False       False      True      False     False      False  \n",
            "1         False       False     False       True     False      False  \n",
            "2         False       False      True      False     False      False  \n",
            "3         False       False      True      False     False      False  \n",
            "4         False       False     False       True     False      False  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 4: Outlier Detection and Handling\n",
        "Instructions\n",
        "Use statistical methods to detect outliers in columns like Fare and Age.\n",
        "Decide on a strategy to handle the identified outliers, such as capping, transformation, or removal.\n",
        "Implement the chosen strategy and assess its impact on the dataset.\n",
        "Hint: Explore methods like IQR (Interquartile Range) and Z-score for outlier detection.\n",
        "\n"
      ],
      "metadata": {
        "id": "sBPYY10YxUO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "df = pd.read_csv('/content/titanic_ds.csv')\n",
        "def detect_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "    return outliers\n",
        "fare_outliers = detect_outliers_iqr(df, 'Fare')\n",
        "age_outliers = detect_outliers_iqr(df, 'Age')\n",
        "\n",
        "print(\"Fare outliers using IQR:\\n\", fare_outliers)\n",
        "print(\"Age outliers using IQR:\\n\", age_outliers)\n",
        "\n",
        "def cap_outliers(df, column):\n",
        "    lower_cap = df[column].quantile(0.01)\n",
        "    upper_cap = df[column].quantile(0.99)\n",
        "    df[column] = np.where(df[column] < lower_cap, lower_cap, df[column])\n",
        "    df[column] = np.where(df[column] > upper_cap, upper_cap, df[column])\n",
        "\n",
        "cap_outliers(df, 'Fare')\n",
        "cap_outliers(df, 'Age')\n",
        "\n",
        "print(\"\\nAfter capping outliers:\")\n",
        "print(df[['Fare', 'Age']].describe())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijssknJA05sC",
        "outputId": "2cec2ee7-005b-419c-a910-81afd7d52f09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fare outliers using IQR:\n",
            "      PassengerId  Survived  Pclass  \\\n",
            "12           904         1       1   \n",
            "24           916         1       1   \n",
            "48           940         1       1   \n",
            "53           945         1       1   \n",
            "59           951         1       1   \n",
            "64           956         0       1   \n",
            "69           961         1       1   \n",
            "74           966         1       1   \n",
            "75           967         0       1   \n",
            "81           973         0       1   \n",
            "96           988         1       1   \n",
            "114         1006         1       1   \n",
            "118         1010         0       1   \n",
            "141         1033         1       1   \n",
            "142         1034         0       1   \n",
            "150         1042         1       1   \n",
            "156         1048         1       1   \n",
            "179         1071         1       1   \n",
            "181         1073         0       1   \n",
            "184         1076         1       1   \n",
            "188         1080         1       3   \n",
            "196         1088         0       1   \n",
            "202         1094         0       1   \n",
            "212         1104         0       2   \n",
            "217         1109         0       1   \n",
            "218         1110         1       1   \n",
            "234         1126         0       1   \n",
            "236         1128         0       1   \n",
            "239         1131         1       1   \n",
            "242         1134         0       1   \n",
            "252         1144         0       1   \n",
            "270         1162         0       1   \n",
            "272         1164         1       1   \n",
            "287         1179         0       1   \n",
            "293         1185         0       1   \n",
            "306         1198         0       1   \n",
            "308         1200         0       1   \n",
            "314         1206         1       1   \n",
            "316         1208         0       1   \n",
            "324         1216         1       1   \n",
            "327         1219         0       1   \n",
            "342         1234         0       3   \n",
            "343         1235         1       1   \n",
            "352         1244         0       2   \n",
            "360         1252         0       3   \n",
            "365         1257         1       3   \n",
            "371         1263         1       1   \n",
            "374         1266         1       1   \n",
            "375         1267         1       1   \n",
            "390         1282         0       1   \n",
            "397         1289         1       1   \n",
            "400         1292         1       1   \n",
            "407         1299         0       1   \n",
            "411         1303         1       1   \n",
            "414         1306         1       1   \n",
            "\n",
            "                                                  Name     Sex   Age  SibSp  \\\n",
            "12       Snyder, Mrs. John Pillsbury (Nelle Stevenson)  female  23.0      1   \n",
            "24     Ryerson, Mrs. Arthur Larned (Emily Maria Borie)  female  48.0      1   \n",
            "48     Bucknell, Mrs. William Robert (Emma Eliza Ward)  female  60.0      0   \n",
            "53                          Fortune, Miss. Ethel Flora  female  28.0      3   \n",
            "59                         Chaudanson, Miss. Victorine  female  36.0      0   \n",
            "64                         Ryerson, Master. John Borie    male  13.0      2   \n",
            "69                 Fortune, Mrs. Mark (Mary McDougald)  female  60.0      1   \n",
            "74                                Geiger, Miss. Amalie  female  35.0      0   \n",
            "75                                  Keeping, Mr. Edwin    male  32.5      0   \n",
            "81                                  Straus, Mr. Isidor    male  67.0      1   \n",
            "96   Cavendish, Mrs. Tyrell William (Julia Florence...  female  76.0      1   \n",
            "114             Straus, Mrs. Isidor (Rosalie Ida Blun)  female  63.0      1   \n",
            "118                               Beattie, Mr. Thomson    male  36.0      0   \n",
            "141                               Daniels, Miss. Sarah  female  33.0      0   \n",
            "142                         Ryerson, Mr. Arthur Larned    male  61.0      1   \n",
            "150              Earnshaw, Mrs. Boulton (Olive Potter)  female  23.0      0   \n",
            "156                                  Bird, Miss. Ellen  female  29.0      0   \n",
            "179  Compton, Mrs. Alexander Taylor (Mary Eliza Ing...  female  64.0      0   \n",
            "181                   Compton, Mr. Alexander Taylor Jr    male  37.0      1   \n",
            "184  Douglas, Mrs. Frederick Charles (Mary Helene B...  female  27.0      1   \n",
            "188                                    Sage, Miss. Ada  female   NaN      8   \n",
            "196                    Spedden, Master. Robert Douglas    male   6.0      0   \n",
            "202                             Astor, Col. John Jacob    male  47.0      1   \n",
            "212                          Deacon, Mr. Percy William    male  17.0      0   \n",
            "217                           Wick, Mr. George Dennick    male  57.0      1   \n",
            "218       Widener, Mrs. George Dunton (Eleanor Elkins)  female  50.0      1   \n",
            "234                          Cumings, Mr. John Bradley    male  39.0      1   \n",
            "236                           Warren, Mr. Frank Manley    male  64.0      1   \n",
            "239        Douglas, Mrs. Walter Donald (Mahala Dutton)  female  48.0      1   \n",
            "242                       Spedden, Mr. Frederic Oakley    male  45.0      1   \n",
            "252                           Clark, Mr. Walter Miller    male  27.0      1   \n",
            "270                       McCaffry, Mr. Thomas Francis    male  46.0      0   \n",
            "272      Clark, Mrs. Walter Miller (Virginia McDowell)  female  26.0      1   \n",
            "287                         Snyder, Mr. John Pillsbury    male  24.0      1   \n",
            "293                              Dodge, Dr. Washington    male  53.0      1   \n",
            "306               Allison, Mr. Hudson Joshua Creighton    male  30.0      1   \n",
            "308                         Hays, Mr. Charles Melville    male  55.0      1   \n",
            "314              White, Mrs. John Stuart (Ella Holmes)  female  55.0      0   \n",
            "316                      Spencer, Mr. William Augustus    male  57.0      1   \n",
            "324                             Kreuchen, Miss. Emilie  female  39.0      0   \n",
            "327        Rosenshine, Mr. George (Mr George Thorne\")\"    male  46.0      0   \n",
            "342                              Sage, Mr. John George    male   NaN      1   \n",
            "343  Cardeza, Mrs. James Warburton Martinez (Charlo...  female  58.0      0   \n",
            "352                                Dibden, Mr. William    male  18.0      0   \n",
            "360                        Sage, Master. William Henry    male  14.5      8   \n",
            "365                     Sage, Mrs. John (Annie Bullen)  female   NaN      1   \n",
            "371                          Wilson, Miss. Helen Alice  female  31.0      0   \n",
            "374              Dodge, Mrs. Washington (Ruth Vidaver)  female  54.0      1   \n",
            "375                           Bowen, Miss. Grace Scott  female  45.0      0   \n",
            "390                         Payne, Mr. Vivian Ponsonby    male  23.0      0   \n",
            "397  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...  female  48.0      1   \n",
            "400                            Bonnell, Miss. Caroline  female  30.0      0   \n",
            "407                         Widener, Mr. George Dunton    male  50.0      1   \n",
            "411    Minahan, Mrs. William Edward (Lillian E Thorpe)  female  37.0      1   \n",
            "414                       Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
            "\n",
            "     Parch        Ticket      Fare            Cabin Embarked  \n",
            "12       0         21228   82.2667              B45        S  \n",
            "24       3      PC 17608  262.3750  B57 B59 B63 B66        C  \n",
            "48       0         11813   76.2917              D15        C  \n",
            "53       2         19950  263.0000      C23 C25 C27        S  \n",
            "59       0      PC 17608  262.3750              B61        C  \n",
            "64       2      PC 17608  262.3750  B57 B59 B63 B66        C  \n",
            "69       4         19950  263.0000      C23 C25 C27        S  \n",
            "74       0        113503  211.5000             C130        C  \n",
            "75       0        113503  211.5000             C132        C  \n",
            "81       0      PC 17483  221.7792          C55 C57        S  \n",
            "96       0         19877   78.8500              C46        S  \n",
            "114      0      PC 17483  221.7792          C55 C57        S  \n",
            "118      0         13050   75.2417               C6        C  \n",
            "141      0        113781  151.5500              NaN        S  \n",
            "142      3      PC 17608  262.3750  B57 B59 B63 B66        C  \n",
            "150      1         11767   83.1583              C54        C  \n",
            "156      0      PC 17483  221.7792              C97        S  \n",
            "179      2      PC 17756   83.1583              E45        C  \n",
            "181      1      PC 17756   83.1583              E52        C  \n",
            "184      1      PC 17558  247.5208          B58 B60        C  \n",
            "188      2      CA. 2343   69.5500              NaN        S  \n",
            "196      2         16966  134.5000              E34        C  \n",
            "202      0      PC 17757  227.5250          C62 C64        C  \n",
            "212      0  S.O.C. 14879   73.5000              NaN        S  \n",
            "217      1         36928  164.8667              NaN        S  \n",
            "218      1        113503  211.5000              C80        C  \n",
            "234      0      PC 17599   71.2833              C85        C  \n",
            "236      0        110813   75.2500              D37        C  \n",
            "239      0      PC 17761  106.4250              C86        C  \n",
            "242      1         16966  134.5000              E34        C  \n",
            "252      0         13508  136.7792              C89        C  \n",
            "270      0         13050   75.2417               C6        C  \n",
            "272      0         13508  136.7792              C89        C  \n",
            "287      0         21228   82.2667              B45        S  \n",
            "293      1         33638   81.8583              A34        S  \n",
            "306      2        113781  151.5500          C22 C26        S  \n",
            "308      1         12749   93.5000              B69        S  \n",
            "314      0      PC 17760  135.6333              C32        C  \n",
            "316      0      PC 17569  146.5208              B78        C  \n",
            "324      0         24160  211.3375              NaN        S  \n",
            "327      0      PC 17585   79.2000              NaN        C  \n",
            "342      9      CA. 2343   69.5500              NaN        S  \n",
            "343      1      PC 17755  512.3292      B51 B53 B55        C  \n",
            "352      0  S.O.C. 14879   73.5000              NaN        S  \n",
            "360      2      CA. 2343   69.5500              NaN        S  \n",
            "365      9      CA. 2343   69.5500              NaN        S  \n",
            "371      0         16966  134.5000          E39 E41        C  \n",
            "374      1         33638   81.8583              A34        S  \n",
            "375      0      PC 17608  262.3750              NaN        C  \n",
            "390      0         12749   93.5000              B24        S  \n",
            "397      1         13567   79.2000              B41        C  \n",
            "400      0         36928  164.8667               C7        S  \n",
            "407      1        113503  211.5000              C80        C  \n",
            "411      0         19928   90.0000              C78        Q  \n",
            "414      0      PC 17758  108.9000             C105        C  \n",
            "Age outliers using IQR:\n",
            "     PassengerId  Survived  Pclass  \\\n",
            "81          973         0       1   \n",
            "96          988         1       1   \n",
            "\n",
            "                                                 Name     Sex   Age  SibSp  \\\n",
            "81                                 Straus, Mr. Isidor    male  67.0      1   \n",
            "96  Cavendish, Mrs. Tyrell William (Julia Florence...  female  76.0      1   \n",
            "\n",
            "    Parch    Ticket      Fare    Cabin Embarked  \n",
            "81      0  PC 17483  221.7792  C55 C57        S  \n",
            "96      0     19877   78.8500      C46        S  \n",
            "\n",
            "After capping outliers:\n",
            "             Fare         Age\n",
            "count  417.000000  332.000000\n",
            "mean    35.063601   30.231481\n",
            "std     51.950059   14.047895\n",
            "min      6.446828    0.857900\n",
            "25%      7.895800   21.000000\n",
            "50%     14.454200   27.000000\n",
            "75%     31.500000   39.000000\n",
            "max    262.375000   64.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 5: Data Standardization and Normalization\n",
        "Instructions\n",
        "Assess the scale and distribution of numerical columns in the dataset.\n",
        "Apply standardization to features with a wide range of values.\n",
        "Normalize data that requires a bounded range, like [0, 1].\n",
        "Hint: Consider using StandardScaler and MinMaxScaler from scikit-learnâ€™s preprocessing module.\n",
        "\n"
      ],
      "metadata": {
        "id": "APiuIKBhIy_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "df = pd.read_csv('/content/titanic_ds.csv')\n",
        "print(\"Scale and distribution of numerical columns in the dataset.:\")\n",
        "print(df.describe())\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "scaler = StandardScaler()\n",
        "df[['Fare', 'Age']] = scaler.fit_transform(df[['Fare', 'Age']])\n",
        "minmax_scaler = MinMaxScaler()\n",
        "df[['Pclass', 'SibSp', 'Parch']] = minmax_scaler.fit_transform(df[['Pclass', 'SibSp', 'Parch']])\n",
        "print(\"\\nAfter Standardization and Normalization:\")\n",
        "print(df.describe())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUvgl5jJAhS0",
        "outputId": "1b91df51-4d62-43f0-daf5-f4e6f06baeb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scale and distribution of numerical columns in the dataset.:\n",
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
            "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
            "std     120.810458    0.481622    0.841838   14.181209    0.896760   \n",
            "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
            "25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n",
            "50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n",
            "75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \n",
            "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  418.000000  417.000000  \n",
            "mean     0.392344   35.627188  \n",
            "std      0.981429   55.907576  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.895800  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.500000  \n",
            "max      9.000000  512.329200  \n",
            "\n",
            "After Standardization and Normalization:\n",
            "       PassengerId    Survived      Pclass           Age       SibSp  \\\n",
            "count   418.000000  418.000000  418.000000  3.320000e+02  418.000000   \n",
            "mean   1100.500000    0.363636    0.632775  2.675236e-17    0.055921   \n",
            "std     120.810458    0.481622    0.420919  1.001509e+00    0.112095   \n",
            "min     892.000000    0.000000    0.000000 -2.125914e+00    0.000000   \n",
            "25%     996.250000    0.000000    0.000000 -6.548515e-01    0.000000   \n",
            "50%    1100.500000    0.000000    1.000000 -2.311178e-01    0.000000   \n",
            "75%    1204.750000    1.000000    1.000000  6.163496e-01    0.125000   \n",
            "max    1309.000000    1.000000    1.000000  3.229374e+00    1.000000   \n",
            "\n",
            "            Parch          Fare  \n",
            "count  418.000000  4.170000e+02  \n",
            "mean     0.043594 -2.342917e-17  \n",
            "std      0.109048  1.001201e+00  \n",
            "min      0.000000 -6.380170e-01  \n",
            "25%      0.000000 -4.966178e-01  \n",
            "50%      0.000000 -3.791690e-01  \n",
            "75%      0.000000 -7.391031e-02  \n",
            "max      1.000000  8.536851e+00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exercise 6: Feature Encoding\n",
        "Instructions\n",
        "Identify categorical columns in the Titanic dataset, such as Sex and Embarked.\n",
        "Use one-hot encoding for nominal variables and label encoding for ordinal variables.\n",
        "Integrate the encoded features back into the main dataset.\n",
        "Hint: Utilize pandas.get_dummies() for one-hot encoding and LabelEncoder from scikit-learn for label encoding.\n",
        "\n"
      ],
      "metadata": {
        "id": "gzF8C2xbBemV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "df = pd.read_csv('/content/titanic_ds.csv')\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical columns:\\n\", categorical_cols)\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'])\n",
        "label_encoder = LabelEncoder()\n",
        "df['Pclass'] = label_encoder.fit_transform(df['Pclass'])\n",
        "print(\"Dataset after feature encoding:\\n\", df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IooU-6CBzk4",
        "outputId": "7b10674a-8553-41fc-db7e-2f19d617638f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns:\n",
            " Index(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], dtype='object')\n",
            "Dataset after feature encoding:\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0          892         0       2   \n",
            "1          893         1       2   \n",
            "2          894         0       1   \n",
            "3          895         0       2   \n",
            "4          896         1       2   \n",
            "\n",
            "                                           Name   Age  SibSp  Parch   Ticket  \\\n",
            "0                              Kelly, Mr. James  34.5      0      0   330911   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  47.0      1      0   363272   \n",
            "2                     Myles, Mr. Thomas Francis  62.0      0      0   240276   \n",
            "3                              Wirz, Mr. Albert  27.0      0      0   315154   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0      1      1  3101298   \n",
            "\n",
            "      Fare Cabin  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
            "0   7.8292   NaN       False      True       False        True       False  \n",
            "1   7.0000   NaN        True     False       False       False        True  \n",
            "2   9.6875   NaN       False      True       False        True       False  \n",
            "3   8.6625   NaN       False      True       False       False        True  \n",
            "4  12.2875   NaN        True     False       False       False        True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 7: Data Transformation for Age Feature\n",
        "Instructions\n",
        "Create age groups (bins) from the Age column to categorize passengers into different age categories.\n",
        "Apply one-hot encoding to the age groups to convert them into binary features.\n",
        "Hint: Use pd.cut() for binning the Age column and pd.get_dummies() for one-hot encoding."
      ],
      "metadata": {
        "id": "OmDBWrCBERp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/titanic_ds.csv')\n",
        "age_bins = [0, 12, 18, 25, 35, 60, 100]\n",
        "age_labels = ['Kid', 'Teen', 'Young Adult', 'Adult', 'Middle-Aged', 'Senior']\n",
        "df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
        "print(\"Dataset with AgeGroup column:\\n\", df[['Age', 'AgeGroup']].head())\n",
        "df = pd.get_dummies(df, columns=['AgeGroup'])\n",
        "print(\"Dataset after one-hot encoding AgeGroup:\\n\", df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWqTbaNXESv1",
        "outputId": "3390dac1-4d1f-40ff-8982-cb1038168323"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with AgeGroup column:\n",
            "     Age     AgeGroup\n",
            "0  34.5        Adult\n",
            "1  47.0  Middle-Aged\n",
            "2  62.0       Senior\n",
            "3  27.0        Adult\n",
            "4  22.0  Young Adult\n",
            "Dataset after one-hot encoding AgeGroup:\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  AgeGroup_Kid  AgeGroup_Teen  \\\n",
            "0   330911   7.8292   NaN        Q         False          False   \n",
            "1   363272   7.0000   NaN        S         False          False   \n",
            "2   240276   9.6875   NaN        Q         False          False   \n",
            "3   315154   8.6625   NaN        S         False          False   \n",
            "4  3101298  12.2875   NaN        S         False          False   \n",
            "\n",
            "   AgeGroup_Young Adult  AgeGroup_Adult  AgeGroup_Middle-Aged  AgeGroup_Senior  \n",
            "0                 False            True                 False            False  \n",
            "1                 False           False                  True            False  \n",
            "2                 False           False                 False             True  \n",
            "3                 False            True                 False            False  \n",
            "4                  True           False                 False            False  \n"
          ]
        }
      ]
    }
  ]
}